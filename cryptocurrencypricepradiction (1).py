# -*- coding: utf-8 -*-
"""CryptocurrencyPricePradiction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z0JeTM6isrUK_0bQ_7PuB93LYk6Y9ECR
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.metrics import MeanSquaredError
from tensorflow.keras.models import Sequential
import tensorflow as tf

import os

from google.colab import drive
import os

# Mount Google Drive
drive.mount('/content/drive')

# Provide the path to your directory inside Google Drive
directory_id = '1aDsT2CF-epSFpiAdPXhhfKsI9TCFfsY8'  # Extracted from the link
directory_path = f'https://drive.google.com/drive/folders/{directory_id}'

# Traverse through the directory and print file paths
for dirname, _, filenames in os.walk(directory_path):
    for filename in filenames:
        print(os.path.join(dirname, filename))

from google.colab import drive
import os

# Mount Google Drive
drive.mount('/content/drive')

# Provide the local path to your directory inside Google Drive
directory_path = '/content/drive/My Drive/Cryptocurrency Historical Prices'

# Print the files in the directory
for filename in os.listdir(directory_path):
    print(filename)



pd.options.mode.chained_assignment = None
pd.options.display.max_columns = 999 #Outputs more colums for dataframes

base = "/content/drive/MyDrive/Cryptocurrency Historical Prices"
datahistory = 60 #Amount of days for data history to use

def coincount(data_drt):
    #This counts the amount of coin files within the given directory.
    coin__Count = 0
    for cryptofile in os.listdir(data_drt):
        if cryptofile.endswith(".csv"):  #It makes sure that only the csv files are being counted.
            coin__Count += 1
    return coin__Count


def get_max_min_data_lengths(data_drt):
    #It finds min and max lengths of the data coin files.
    lengthmax = 0
    lengthmin = float("inf")  #Actiavtes lengthmin to be infinity
    for cryptofile in os.listdir(data_drt):
        if cryptofile.endswith(".csv"):
            fD = pd.read_csv(data_drt + "/" + cryptofile, parse_dates=['Date'])
            lengthdata = fD.shape[0]
            lengthmax = max(lengthmax, lengthdata)
            lengthmin = min(lengthmin, lengthdata)
    return lengthmax,lengthmin


def read_process_coin_data(data_drt, indexCoin):
    #It reads and processes a specific coin.
    cryptofile = os.listdir(data_drt)[indexCoin]
    fD = pd.read_csv(data_drt + "/" + cryptofile, parse_dates=['Date'])
    symbolCoin = cryptofile[5:-4]
    lengthdata = fD.shape[0]
    pricesclosing = fD['closed'].values
    return symbolCoin, lengthdata, pricesclosing


def read_data(data_drt, datahistory):
    #It reads and processes the cryptocurrency data.
    coinNum = coin__Count(data_drt)
    maxlengthdata = get_max_min_data_lengths(data_drt)  #length_min Discarded.
    pricesclosingdata = np.zeros((coinNum, maxlengthdata))
    coinlengthsdata = np.zeros(coinNum, dtype=int)

    for indexCoin in range(coinNum):
        symbolCoin, lengthdata, pricesclosing = read_process_coin_data(data_drt, indexCoin)
        print(indexCoin, symbolCoin, lengthdata)
        priceslosingdata[indexCoin, 0:lengthdata] = pricesclosing
        coinlengthsdata[indexCoin] = lengthdata

def read_data ():
#Reading and processing all coin's data in the exact directory.

    coinNum = 0
    for name in os.listdir(base):
        coinNum += 1 #This counts the amount of files with coins.

    lengthmax, lengthmin = 0, 1000000 #Intiating along a big value.
    for name in os.listdir(base):
        fD = pd.read_csv(base + "/" + name, parse_dates=['Date'])
        thelength = fD.shape[0]
        if lengthmax < thelength:
            lengthmax = thelength
        if lengthmin > thelength:
            lengthmin = thelength #Won't really be used but stored for some reference.

#Activates arrays to keep coins data
    info = np.zeros ((coinNum, lengthmax))
    Slength = np.zeros(coinNum, dtype = int)
    i = 0
    for name in os.listdir(base):
        coinSymb = name[5:-4] #Extracting the symbol of the coin from the file name.
        fD = pd.read_csv(base + "/" + name, parse_dates=['Date'])
        thelength = fD.shape[0]

        #Storing coin info.
        Slength[i] = thelength
        print (i, coinSymb, thelength)

        info[i, 0:thelength] = fD['Close'].values
        i += 1


    return coinNum, Slength, info

coinNum, Slength, info = read_data ()
print ("Coin amount: ", coinNum, ".")

def data_scale(info, Slength):

    coinNum = info.shape[0] #More cleaner name for the variable.
    shift_info = np.zeros(coinNum)
    factor_scale = np.zeros(coinNum)
    #^^^ shift_info and factor_scale have descriptive name.

    for i in range (coinNum):
        valMax = info[i,:Slength[i]].max()
        valMin = info[i, :Slength[i]].min()
        #^^^ Clearing calculation ^^^
        shift_info[i] = valMin #This stores the info of shift value of the info.
        factor_scale[i] = valMax - valMin #Calculating the factor scale.

        if factor_scale[i] == 0:
            raise ValueError("Division by zero encountered during scaling.")

        info[i,0:Slength[i]] = (info[i,0:Slength[i]]-shift_info[i])/factor_scale[i]
    return (shift_info, factor_scale) #Scaling the info and scale factor

shift_info, factor_scale = data_scale (info, Slength)

def sequence (info, Slength, begin, finish):

    assert len(info) == len(Slength), "Unmatched data length."

    #Intiate blank lists to keep targets and sequences.
    A = []
    B = []

    #It only crosses over the exact coins.
    for j in range (begin, finish):
        for i in range(datahistory, Slength[j]):
            #Append input sequence and its compatible value target.
            A.append(info[j, i-datahistory:i])
            B.append(info[j, i])

    #Numpy arrays returned to LSTM with proper shapes.
    return np.array(A)[:, :, np.newaxis], np.array(B)


#Creating the validation, training, and test sequence.
X_val, Y_val = sequence(info, Slength, 18, 22)
print ("Approximately", Y_val.shape[0], "Sequence for validation.")



X_test, Y_test = sequence(info, Slength, 22, 23)
print ("Approximately", Y_test.shape[0], "Sequence for testing.")


X_train, Y_train = sequence(info, Slength, 0, 18)
print ("Approximately", Y_train.shape[0], "Sequence for training.")

def lstm_model ():

    """
    Building an LSTM model with multi-layer for the time data prediction.
    Making an LSTM model for the crypto currency price prediction machine is quite a great approach because of great it is at fetching long-term
    dependencies, which makes it ideal for sequence and prediction tasks. LSTM can incorporate conections with feedback, premitting it to analyze
    high amount of sequences of data.

    """

    model_lstm = tf.keras.Sequential()

    #The beginning of this model with the first LSTM layer, with 130 units, giving back the sequences for a bigger model.
    model_lstm.add(tf.keras.layers.LSTM(130, return_sequences=True, input_shape= (datahistory, 1)))

    #Here is the second LSTM layer coming in with 70 units, however not giving or returning the sequences.
    model_lstm.add(tf.keras.layers.LSTM(70, return_sequences=False))

    #A layer dense made with 30 units for medial processing.
    model_lstm.add(tf.keras.layers.Dense(30))

    #Another dense layer with is the output layer with only 1 unit for prediction.
    model_lstm.add(tf.keras.layers.Dense(1))

    #For compiling the model and utilizing the adam optimizer, and mean squared error loss.
    model_lstm.compile(optimizer='adam', loss='mean_squared_error')

    #Time to sum up the model for an overview.
    model_lstm.summary()

    return model_lstm

#Creating a specimen of LSTM model.
model_lstm = lstm_model()

#Model training process. It stores the training history for examination, indication of a validation set, adjusting batch size for optimization,
#And epochs increased for the machine to have better learning.
training = model_lstm.fit(X_train, Y_train, validation_data = (X_val, Y_val), batch_size=32, epochs=10)

def stats_reveal (training):
    #An understanding the model's validation & training loss over the epochs.


    #Plotting the validation and training curves of loss.
    plt.plot(training.history['loss'])
    plt.plot(training.history['val_loss'])


    #Setting the graph labels and tilte.
    plt.title("Model")
    plt.xlabel("Epoch")
    plt.ylabel("Loss Prediction")
    plt.legend(["Training Loss", "Validation Loss"])

    #Outputs the graph.
    plt.show()

#Summons the function to get a visualization on the curves loss.
stats_reveal (training)

#Activating the model's predictions on the test dataset.
prognosis = model_lstm.predict(X_test)

plt.title("Model's prediction vs real prices")

#Calculating the Root Mean Squared Error (RMSE) to determine the prediction's accuracy.
"""
Root Mean Squared Error (RMSE) can be used here to measure the averaging difference that sit between the values predicted by the
model (in this case, the LSTM model) and its exact values.

"""
rmse = np.sqrt(np.mean(((prognosis - Y_test) ** 2)))
print("RSME: ", rmse)

#Plots the prediction data.
plt.plot(prognosis*factor_scale[20] + shift_info[20])

#Plots the real data.
plt.plot(Y_test*factor_scale[20] + shift_info[20])

#Outputs the graph and legend.
plt.legend(["Predictions","Real data"])
plt.show()

import numpy as np

# Calculate Root Mean Squared Error (RMSE)
def calculate_rmse(predictions, targets):
    return np.sqrt(np.mean((predictions - targets) ** 2))

# Calculate RMSE for the predictions
rmse = calculate_rmse(prognosis, Y_test)

print("RMSE: ", rmse)

# Define the threshold
threshold = 0.5

# Calculate accuracy based on the threshold
correct_predictions = np.abs(prognosis - Y_test) < threshold
accuracy = np.mean(correct_predictions)

print("Accuracy: ", accuracy)

# Take input from the user for the cryptocurrency name
coin_name = input("Enter the name of the cryptocurrency: ")

# Take input from the user for the number of years to predict
years = int(input("Enter the number of years to predict: "))

# Find the index of the cryptocurrency in the list of coins
coin_index = None
for i, name in enumerate(os.listdir(base)):
    if coin_name.lower() in name.lower():
        coin_index = i
        break

if coin_index is None:
    print("Cryptocurrency not found.")
else:
    # Generate sequences for the specified cryptocurrency
    X, _ = sequence(info, Slength, coin_index, coin_index + 1)

    # Predict cryptocurrency prices for the specified number of years
    predictions = model_lstm.predict(X)

    # Extract the last prediction for each year
    last_prediction = predictions[:, -1]

    # Convert the predictions back to the original scale
    scaled_predictions = last_prediction * factor_scale[coin_index] + shift_info[coin_index]

    # Display the predicted prices
    print(f"Predicted prices for {coin_name} for the next {years} years:")
    for i in range(years):
        print(f"Year {i + 1}: ${scaled_predictions[i]}")